{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from utilities import *\n",
    "import opendp.prelude as dp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:8: SyntaxWarning: invalid escape sequence '\\k'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\k'\n",
      "C:\\Users\\kshub\\AppData\\Local\\Temp\\ipykernel_1484\\2292770000.py:8: SyntaxWarning: invalid escape sequence '\\k'\n",
      "  path = \"C:\\\\Users\\kshub\\\\OneDrive\\\\Documents\\\\PET_phase_2\\\\Technical_Phase_Data\\\\technical_phase_data.csv\"\n"
     ]
    }
   ],
   "source": [
    "dp.enable_features(\"contrib\", \"floating-point\", \"honest-but-curious\")\n",
    "\n",
    "# PUBLIC INFO\n",
    "# start_date, end_date = datetime(2020, 9, 1), datetime(2021, 3, 31)\n",
    "# time_col = \"date\"\n",
    "\n",
    "# DATA\n",
    "path = \"C:\\\\Users\\kshub\\\\OneDrive\\\\Documents\\\\PET_phase_2\\\\Technical_Phase_Data\\\\technical_phase_data.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_domain(public_key_sets=None):\n",
    "    \"\"\"Creates a domain representing the set of all data frames.\n",
    "    \n",
    "    Assumes column names and types are public information.\n",
    "    Key sets optionally named for columns in `public_key_sets` are considered public information.\n",
    "\n",
    "    Two data frames differing in their public information \n",
    "    are considered to have a data set distance of infinity.\n",
    "    \"\"\"\n",
    "    return dp.user_domain(\n",
    "        \"DataFrameDomain\", lambda x: isinstance(x, pd.DataFrame), public_key_sets\n",
    "    )\n",
    "\n",
    "\n",
    "def series_domain():\n",
    "    \"\"\"Creates a domain representing the set of all series.\n",
    "\n",
    "    Assumes series name and type are public information.\n",
    "\n",
    "    Two series differing in their public information \n",
    "    are considered to have a data set distance of infinity.\n",
    "    \"\"\"\n",
    "    return dp.user_domain(\"SeriesDomain\", lambda x: isinstance(x, pd.Series))\n",
    "\n",
    "def identifier_distance():\n",
    "    \"\"\"Symmetric distance between the id sets.\"\"\"\n",
    "    return dp.user_distance(\"IdentifierDistance\")\n",
    "\n",
    "\n",
    "def approx_concentrated_divergence():\n",
    "    \"\"\"symmetric distance between the id sets\"\"\"\n",
    "    return dp.user_distance(\"ApproxConcentratedDivergence()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocess_location():\n",
    "    \"\"\"Create a 1-stable transformation to bin `merch_postal_code` by city\"\"\"\n",
    "\n",
    "    def categorize_city(code):\n",
    "        if code.startswith(\"5\"):\n",
    "            return \"Medellin\"\n",
    "        elif code.startswith(\"11\"):\n",
    "            return \"Bogota\"\n",
    "        elif code.startswith(\"70\"):\n",
    "            return \"Brasilia\"\n",
    "        else:\n",
    "            return \"Santiago\"\n",
    "\n",
    "    def location_preprocess(df):\n",
    "        loc_df = df.copy()\n",
    "        # Convert merchant_postal_code into str type\n",
    "        loc_df[\"merch_postal_code\"] = loc_df[\"merch_postal_code\"].astype(str)\n",
    "        # Apply the function to create a new column\n",
    "        loc_df[\"city\"] = loc_df[\"merch_postal_code\"].apply(\n",
    "            categorize_city\n",
    "        )\n",
    "        return loc_df\n",
    "\n",
    "    return dp.t.make_user_transformation(\n",
    "        input_domain=dataframe_domain(),\n",
    "        input_metric=identifier_distance(),\n",
    "        output_domain=dataframe_domain(),\n",
    "        output_metric=identifier_distance(),\n",
    "        function=location_preprocess,\n",
    "        stability_map=lambda d_in: d_in,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocess_merchant():\n",
    "    \"\"\"Create a 1-stable transformation to bin `merch_postal_code` by city\"\"\"\n",
    "\n",
    "    def categorize_merchant(merch):\n",
    "        if merch in ['Hotels/Motels','Restaurants','Bars/Discotheques']:\n",
    "            return \"luxury\"\n",
    "        elif merch in ['Grocery Stores/Supermarkets','Drug Stores/Pharmacies','General Retail Stores','Utilities: Electric, Gas, Water','Hospitals']:\n",
    "            return \"essential\"\n",
    "        else:\n",
    "            return \"other\"\n",
    "\n",
    "    def merchant_preprocess(df):\n",
    "        loc_df = df.copy()\n",
    "        # Convert merchant_postal_code into str type\n",
    "        loc_df[\"merch_category\"] = loc_df[\"merch_category\"].astype(str)\n",
    "        # Apply the function to create a new column\n",
    "        loc_df[\"merch_super_category\"] = loc_df[\"merch_category\"].apply(\n",
    "            categorize_merchant\n",
    "        )\n",
    "        return loc_df\n",
    "\n",
    "    return dp.t.make_user_transformation(\n",
    "        input_domain=dataframe_domain(),\n",
    "        input_metric=identifier_distance(),\n",
    "        output_domain=dataframe_domain(),\n",
    "        output_metric=identifier_distance(),\n",
    "        function=merchant_preprocess,\n",
    "        stability_map=lambda d_in: d_in,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_truncate_time(start_date, end_date, time_col):\n",
    "    \"\"\"Create a transformation that filters the data to a given time frame.\n",
    "    \n",
    "    WARNING: Assumes that the data has at most one contribution per individual per week.\n",
    "    \"\"\"\n",
    "    number_of_timesteps = (end_date - start_date).days // 7\n",
    "\n",
    "    def time_preprocess(df):\n",
    "        df = df.copy()\n",
    "\n",
    "        # Convert time_col into datetime type\n",
    "        df[time_col] = pd.to_datetime(df[time_col])\n",
    "\n",
    "        # Filter the DataFrame based on the specified dates\n",
    "        return df[(df[time_col] >= start_date) & (df[time_col] <= end_date)]\n",
    "\n",
    "    return dp.t.make_user_transformation(\n",
    "        input_domain=dataframe_domain(),\n",
    "        input_metric=identifier_distance(),\n",
    "        output_domain=dataframe_domain(),\n",
    "        output_metric=dp.symmetric_distance(),\n",
    "        function=time_preprocess,\n",
    "        stability_map=lambda d_in: d_in * number_of_timesteps,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sum_by(column, by, bounds):\n",
    "    \"\"\"Create a transformation that computes the grouped bounded sum of `column`\"\"\"\n",
    "    L, U = bounds\n",
    "    def function(df):\n",
    "        df = df.copy()\n",
    "        df[column] = df[column].clip(*bounds)\n",
    "        return df.groupby(by)[column].sum()\n",
    "\n",
    "    return dp.t.make_user_transformation(\n",
    "        input_domain=dataframe_domain(),\n",
    "        input_metric=dp.symmetric_distance(),\n",
    "        output_domain=series_domain(),\n",
    "        output_metric=dp.l2_distance(T=float),\n",
    "        function=function,\n",
    "        stability_map=lambda d_in: np.sqrt(d_in) * max(abs(L), U),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maximum nb_transaction entry for any category is 454. Assuming the bound of [0, 454]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_private_sum_by(column, by, bounds, scale):\n",
    "    \"\"\"Create a measurement that computes the grouped bounded sum of `column`\"\"\"\n",
    "    space = dp.vector_domain(dp.atom_domain(T=int)), dp.l2_distance(T=float)\n",
    "    m_gauss = space >> dp.m.then_gaussian(scale)\n",
    "    t_sum = make_sum_by(column, by, bounds)\n",
    "\n",
    "    def function(df):\n",
    "        exact = t_sum(df)\n",
    "        # print(exact)\n",
    "        noisy_sum = pd.Series(\n",
    "            np.maximum(m_gauss(exact.to_numpy().flatten()), 0), \n",
    "        )\n",
    "        # print(noisy_sum)\n",
    "        noisy_sum=noisy_sum.to_frame(name=\"df_nb_transactions\")\n",
    "        noisy_sum[\"postal_code\"] = exact.index\n",
    "        return noisy_sum\n",
    "\n",
    "    return dp.m.make_user_measurement(\n",
    "        input_domain=dataframe_domain(public_key_sets=[by]),\n",
    "        input_metric=dp.symmetric_distance(),\n",
    "        output_measure=dp.zero_concentrated_divergence(T=float),\n",
    "        function=function,\n",
    "        privacy_map=lambda d_in: m_gauss.map(t_sum.map(d_in)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filter(column,entry, sensetivity:int= 1):\n",
    "        \"\"\"filters offline entries\"\"\"\n",
    "        \n",
    "        def function(df):\n",
    "            df = df.copy()\n",
    "            return df[(df[column] == entry)]\n",
    "\n",
    "\n",
    "        return dp.t.make_user_transformation(\n",
    "        input_domain=dataframe_domain(),\n",
    "        input_metric=identifier_distance(),\n",
    "        output_domain=dataframe_domain(),\n",
    "        output_metric=identifier_distance(),\n",
    "        function=function,\n",
    "        stability_map=lambda d_in: d_in* sensetivity,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 days, 3:25:42.857143\n",
      "2486.6604110734543\n",
      "30917.389778\n"
     ]
    }
   ],
   "source": [
    "print((end_date-start_date)/7)\n",
    "print(np.sqrt(30)*454)\n",
    "space = dp.vector_domain(dp.atom_domain(T=int)), dp.l2_distance(T=float)\n",
    "m_gauss = space >> dp.m.then_gaussian(10.0)\n",
    "print(m_gauss.map(2486.66))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df_nb_transactions</th>\n",
       "      <th>postal_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>182279</td>\n",
       "      <td>500001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184214</td>\n",
       "      <td>500002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181064</td>\n",
       "      <td>500003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>178537</td>\n",
       "      <td>500004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202214</td>\n",
       "      <td>500005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>189760</td>\n",
       "      <td>500006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>205059</td>\n",
       "      <td>500007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>166498</td>\n",
       "      <td>500008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>194857</td>\n",
       "      <td>500009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>188940</td>\n",
       "      <td>500010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>175241</td>\n",
       "      <td>500011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>165548</td>\n",
       "      <td>500012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>190520</td>\n",
       "      <td>500013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>214835</td>\n",
       "      <td>500014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>191982</td>\n",
       "      <td>500015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>192561</td>\n",
       "      <td>500016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>193773</td>\n",
       "      <td>500017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>218487</td>\n",
       "      <td>500020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>205337</td>\n",
       "      <td>500021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>214306</td>\n",
       "      <td>500022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>185689</td>\n",
       "      <td>500023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>212885</td>\n",
       "      <td>500024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>206188</td>\n",
       "      <td>500025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>185096</td>\n",
       "      <td>500026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>202569</td>\n",
       "      <td>500027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>180771</td>\n",
       "      <td>500028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>207616</td>\n",
       "      <td>500030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>207331</td>\n",
       "      <td>500031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>221121</td>\n",
       "      <td>500032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>193677</td>\n",
       "      <td>500033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>176488</td>\n",
       "      <td>500034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>190031</td>\n",
       "      <td>500035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>176728</td>\n",
       "      <td>500036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>163643</td>\n",
       "      <td>500037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>178735</td>\n",
       "      <td>500040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>185477</td>\n",
       "      <td>500041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>188734</td>\n",
       "      <td>500042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>228701</td>\n",
       "      <td>500043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>165526</td>\n",
       "      <td>500044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>182993</td>\n",
       "      <td>500046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>190205</td>\n",
       "      <td>500047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>183710</td>\n",
       "      <td>55411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    df_nb_transactions postal_code\n",
       "0               182279      500001\n",
       "1               184214      500002\n",
       "2               181064      500003\n",
       "3               178537      500004\n",
       "4               202214      500005\n",
       "5               189760      500006\n",
       "6               205059      500007\n",
       "7               166498      500008\n",
       "8               194857      500009\n",
       "9               188940      500010\n",
       "10              175241      500011\n",
       "11              165548      500012\n",
       "12              190520      500013\n",
       "13              214835      500014\n",
       "14              191982      500015\n",
       "15              192561      500016\n",
       "16              193773      500017\n",
       "17              218487      500020\n",
       "18              205337      500021\n",
       "19              214306      500022\n",
       "20              185689      500023\n",
       "21              212885      500024\n",
       "22              206188      500025\n",
       "23              185096      500026\n",
       "24              202569      500027\n",
       "25              180771      500028\n",
       "26              207616      500030\n",
       "27              207331      500031\n",
       "28              221121      500032\n",
       "29              193677      500033\n",
       "30              176488      500034\n",
       "31              190031      500035\n",
       "32              176728      500036\n",
       "33              163643      500037\n",
       "34              178735      500040\n",
       "35              185477      500041\n",
       "36              188734      500042\n",
       "37              228701      500043\n",
       "38              165526      500044\n",
       "39              182993      500046\n",
       "40              190205      500047\n",
       "41              183710       55411"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df.copy()\n",
    "bounds = (0, 454)\n",
    "start_date, end_date = datetime(2020, 9, 1), datetime(2021, 3, 31)\n",
    "columns = \"nb_transactions\"\n",
    "by = \"merch_postal_code\"\n",
    "scale=10.0\n",
    "column=\"transaction_type\"\n",
    "entry=\"OFFLINE\"\n",
    "city_col=\"city\"\n",
    "City_entry=\"Medellin\"\n",
    "time_col=\"date\"\n",
    "hotspot_predictor=(\n",
    "    make_preprocess_location()\n",
    "    >>make_filter(column,entry)\n",
    "    >>make_filter(city_col,City_entry)\n",
    "    >>make_truncate_time(start_date, end_date, time_col)\n",
    "    >>make_private_sum_by(columns, by, bounds, scale)\n",
    ")\n",
    "# print(hotspot_predictor.map(1))\n",
    "output=hotspot_predictor(df_new)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df_nb_transactions</th>\n",
       "      <th>merch_postal_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merch_postal_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500001</th>\n",
       "      <td>182289</td>\n",
       "      <td>500001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500002</th>\n",
       "      <td>184220</td>\n",
       "      <td>500002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500003</th>\n",
       "      <td>181035</td>\n",
       "      <td>500003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500004</th>\n",
       "      <td>178532</td>\n",
       "      <td>500004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500005</th>\n",
       "      <td>202198</td>\n",
       "      <td>500005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500006</th>\n",
       "      <td>189746</td>\n",
       "      <td>500006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500007</th>\n",
       "      <td>205037</td>\n",
       "      <td>500007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500008</th>\n",
       "      <td>166527</td>\n",
       "      <td>500008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500009</th>\n",
       "      <td>194847</td>\n",
       "      <td>500009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500010</th>\n",
       "      <td>188928</td>\n",
       "      <td>500010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500011</th>\n",
       "      <td>175254</td>\n",
       "      <td>500011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500012</th>\n",
       "      <td>165550</td>\n",
       "      <td>500012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500013</th>\n",
       "      <td>190541</td>\n",
       "      <td>500013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500014</th>\n",
       "      <td>214842</td>\n",
       "      <td>500014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500015</th>\n",
       "      <td>191981</td>\n",
       "      <td>500015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500016</th>\n",
       "      <td>192569</td>\n",
       "      <td>500016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500017</th>\n",
       "      <td>193754</td>\n",
       "      <td>500017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500020</th>\n",
       "      <td>218485</td>\n",
       "      <td>500020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500021</th>\n",
       "      <td>205337</td>\n",
       "      <td>500021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500022</th>\n",
       "      <td>214329</td>\n",
       "      <td>500022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500023</th>\n",
       "      <td>185693</td>\n",
       "      <td>500023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500024</th>\n",
       "      <td>212892</td>\n",
       "      <td>500024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500025</th>\n",
       "      <td>206170</td>\n",
       "      <td>500025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500026</th>\n",
       "      <td>185111</td>\n",
       "      <td>500026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500027</th>\n",
       "      <td>202565</td>\n",
       "      <td>500027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500028</th>\n",
       "      <td>180751</td>\n",
       "      <td>500028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500030</th>\n",
       "      <td>207605</td>\n",
       "      <td>500030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500031</th>\n",
       "      <td>207331</td>\n",
       "      <td>500031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500032</th>\n",
       "      <td>221120</td>\n",
       "      <td>500032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500033</th>\n",
       "      <td>193701</td>\n",
       "      <td>500033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500034</th>\n",
       "      <td>176484</td>\n",
       "      <td>500034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500035</th>\n",
       "      <td>190046</td>\n",
       "      <td>500035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500036</th>\n",
       "      <td>176729</td>\n",
       "      <td>500036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500037</th>\n",
       "      <td>163653</td>\n",
       "      <td>500037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500040</th>\n",
       "      <td>178753</td>\n",
       "      <td>500040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500041</th>\n",
       "      <td>185478</td>\n",
       "      <td>500041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500042</th>\n",
       "      <td>188737</td>\n",
       "      <td>500042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500043</th>\n",
       "      <td>228689</td>\n",
       "      <td>500043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500044</th>\n",
       "      <td>165515</td>\n",
       "      <td>500044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500046</th>\n",
       "      <td>182984</td>\n",
       "      <td>500046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500047</th>\n",
       "      <td>190185</td>\n",
       "      <td>500047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55411</th>\n",
       "      <td>183691</td>\n",
       "      <td>55411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   df_nb_transactions merch_postal_code\n",
       "merch_postal_code                                      \n",
       "500001                         182289            500001\n",
       "500002                         184220            500002\n",
       "500003                         181035            500003\n",
       "500004                         178532            500004\n",
       "500005                         202198            500005\n",
       "500006                         189746            500006\n",
       "500007                         205037            500007\n",
       "500008                         166527            500008\n",
       "500009                         194847            500009\n",
       "500010                         188928            500010\n",
       "500011                         175254            500011\n",
       "500012                         165550            500012\n",
       "500013                         190541            500013\n",
       "500014                         214842            500014\n",
       "500015                         191981            500015\n",
       "500016                         192569            500016\n",
       "500017                         193754            500017\n",
       "500020                         218485            500020\n",
       "500021                         205337            500021\n",
       "500022                         214329            500022\n",
       "500023                         185693            500023\n",
       "500024                         212892            500024\n",
       "500025                         206170            500025\n",
       "500026                         185111            500026\n",
       "500027                         202565            500027\n",
       "500028                         180751            500028\n",
       "500030                         207605            500030\n",
       "500031                         207331            500031\n",
       "500032                         221120            500032\n",
       "500033                         193701            500033\n",
       "500034                         176484            500034\n",
       "500035                         190046            500035\n",
       "500036                         176729            500036\n",
       "500037                         163653            500037\n",
       "500040                         178753            500040\n",
       "500041                         185478            500041\n",
       "500042                         188737            500042\n",
       "500043                         228689            500043\n",
       "500044                         165515            500044\n",
       "500046                         182984            500046\n",
       "500047                         190185            500047\n",
       "55411                          183691             55411"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"df_nb_transactions\"]\n",
    "#extract merch_postal_code from the output index and add to it as a column\n",
    "output[\"merch_postal_code\"]=output.index\n",
    "#reset the index\n",
    "# output.reset_index(drop=True, inplace=True)\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70675: (5.799656694505305, -76.56247484293878)\n",
      "70374: (7.67716584722098, -76.92939720574404)\n",
      "70253: (6.312225635799086, -74.13886063563739)\n",
      "70355: (7.276436263604821, -76.03768649371906)\n",
      "70336: (6.863950520097977, -76.64515475022561)\n",
      "70354: (5.631456658330162, -76.43180706368042)\n",
      "70640: (7.692717677913366, -76.1071878825416)\n",
      "70345: (6.821027928450581, -75.77354385165218)\n",
      "70353: (6.9413765640780305, -74.50645842830441)\n",
      "70710: (7.683644671021737, -75.5213181926195)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "postal_codes=df[\"merch_postal_code\"].unique()\n",
    "\n",
    "postal_code = {\n",
    "    'Medellin': [ code  for code in postal_codes if code < 110000],\n",
    "    'Bogota': [ code  for code in postal_codes if code >= 110000 and code < 500000],\n",
    "    'Brasilia': [ code  for code in postal_codes if code >= 500000 and code < 7500000],\n",
    "    'Santiago': [ code  for code in postal_codes if code >= 7500000]\n",
    "}\n",
    "\n",
    "# Reference coordinates\n",
    "reference_coords = {\n",
    "    \"Medellin\": (6.2476, -75.5658),\n",
    "    \"Bogota\": (4.7110, -74.0721),\n",
    "    \"Brasilia\": (-15.7975, -47.8919),\n",
    "    \"Santiago\": (-33.4489, -70.6693)\n",
    "}\n",
    "\n",
    "# Function to generate unique coordinates\n",
    "def generate_unique_coords(base_lat, base_lon, num_coords):\n",
    "    coords = []\n",
    "    for _ in range(num_coords):\n",
    "        # Slightly vary the base coordinates\n",
    "        lat_variation = random.uniform(-1.5, +1.5)\n",
    "        lon_variation = random.uniform(-1.5, +1.5)\n",
    "        new_lat = base_lat + lat_variation\n",
    "        new_lon = base_lon + lon_variation\n",
    "        coords.append((new_lat, new_lon))\n",
    "    return coords\n",
    "\n",
    "# Assign unique coordinates to each postal code\n",
    "postal_code_coords = {}\n",
    "for segment, codes in postal_code.items():\n",
    "    base_lat, base_lon = reference_coords[segment]\n",
    "    unique_coords = generate_unique_coords(base_lat, base_lon, len(codes))\n",
    "    for code, coord in zip(codes, unique_coords):\n",
    "        postal_code_coords[code] = coord\n",
    "\n",
    "# Print the results\n",
    "for code, coord in list(postal_code_coords.items())[:10]:\n",
    "    print(f'{code}: {coord}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Latitude'], df['Longitude'] = zip(*df['merch_postal_code'].map(postal_code_coords))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hotspot_analyser(df:pd.DataFrame, start_date:datetime,end_date:datetime,city_filter:str, nb_postal_codes: int,epsilon:float):\n",
    "    \"\"\"final function to predict hotspots\"\"\"\n",
    "    bounds = (0, 600)\n",
    "    transaction_data_col = \"nb_transactions\"\n",
    "    postal_code_groupby_col = \"merch_postal_code\"\n",
    "    transaction_type_col = \"transaction_type\"\n",
    "    transaction_type_filter = \"OFFLINE\"\n",
    "    city_col=\"city\"\n",
    "    time_col=\"date\"\n",
    "\n",
    "    \"\"\"time steps calculation\"\"\"\n",
    "    nb_timesteps = (end_date - start_date).days // 7\n",
    "\n",
    "    \"\"\"scale calculation\"\"\"\n",
    "    scale=(3.0*nb_postal_codes*nb_timesteps)/epsilon\n",
    "\n",
    "    new_df=df.copy()\n",
    "\n",
    "\n",
    "    hotspot_predictor=(\n",
    "    make_preprocess_location()\n",
    "    >>make_filter(transaction_type_col,transaction_type_filter)\n",
    "    >>make_filter(city_col,city_filter,nb_postal_codes)\n",
    "    >>make_truncate_time(start_date, end_date, time_col)\n",
    "    >>make_private_sum_by(transaction_data_col, postal_code_groupby_col, bounds, scale)\n",
    "   )\n",
    "\n",
    "    return hotspot_predictor(new_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        0\n",
      "merch_postal_code        \n",
      "500001             182127\n",
      "500002             184834\n",
      "500003             180723\n",
      "500004             178663\n",
      "500005             202160\n",
      "500006             190032\n",
      "500007             204808\n",
      "500008             166404\n",
      "500009             194555\n",
      "500010             189101\n",
      "500011             175437\n",
      "500012             165264\n",
      "500013             190181\n",
      "500014             214967\n",
      "500015             191939\n",
      "500016             193132\n",
      "500017             194186\n",
      "500020             218432\n",
      "500021             205058\n",
      "500022             215002\n",
      "500023             186325\n",
      "500024             213090\n",
      "500025             206436\n",
      "500026             185552\n",
      "500027             203101\n",
      "500028             180149\n",
      "500030             207686\n",
      "500031             207353\n",
      "500032             221942\n",
      "500033             193726\n",
      "500034             177103\n",
      "500035             189928\n",
      "500036             176520\n",
      "500037             163407\n",
      "500040             178941\n",
      "500041             185563\n",
      "500042             188988\n",
      "500043             228932\n",
      "500044             165859\n",
      "500046             182936\n",
      "500047             190162\n",
      "55411              183695\n"
     ]
    }
   ],
   "source": [
    "print(hotspot_analyser(df,start_date,end_date,\"Medellin\",42,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobility_analyser(df:pd.DataFrame,start_date:datetime,end_date:datetime,city_filter: str, epsilon:float):\n",
    "    \"\"\"final function to predict hotspots\"\"\"\n",
    "    bounds = (0, 600)\n",
    "    transaction_data_col = \"nb_transactions\"\n",
    "    groupby_col = \"date\"\n",
    "\n",
    "    city_col=\"city\"\n",
    "    time_col=\"date\"\n",
    "    merch_category_col=\"merch_category\"\n",
    "    merch_filter=\"Airlines\"\n",
    "\n",
    "    \"\"\"time steps calculation\"\"\"\n",
    "    nb_timesteps = (end_date - start_date).days // 7\n",
    "\n",
    "    \"\"\"scale calculation\"\"\"\n",
    "    scale=(3.0*nb_timesteps*nb_timesteps)/epsilon\n",
    "\n",
    "    new_df=df.copy()\n",
    "\n",
    "\n",
    "    hotspot_predictor=(\n",
    "    make_preprocess_location()\n",
    "    >>make_filter(city_col,city_filter)\n",
    "    >>make_filter(merch_category_col,merch_filter)\n",
    "    >>make_truncate_time(start_date, end_date, time_col)\n",
    "    >>make_private_sum_by(transaction_data_col, groupby_col, bounds, scale)\n",
    "   )\n",
    "\n",
    "    return hotspot_predictor(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0\n",
      "date            \n",
      "2020-09-01  1418\n",
      "2020-09-08   860\n",
      "2020-09-15  1273\n",
      "2020-09-22  1278\n",
      "2020-09-29   937\n",
      "2020-10-06  1413\n",
      "2020-10-13  1185\n",
      "2020-10-20  1055\n",
      "2020-10-27   981\n",
      "2020-11-03  1431\n",
      "2020-11-10  1260\n",
      "2020-11-17  1270\n",
      "2020-11-24  1736\n",
      "2020-12-01  1331\n",
      "2020-12-08  1081\n",
      "2020-12-15  1601\n",
      "2020-12-22  1591\n",
      "2020-12-29  1300\n",
      "2021-01-05  1082\n",
      "2021-01-12  1873\n",
      "2021-01-19  1244\n",
      "2021-01-26  1223\n",
      "2021-02-02  1560\n",
      "2021-02-09  1747\n",
      "2021-02-16  1267\n",
      "2021-02-23  2057\n",
      "2021-03-02  1117\n",
      "2021-03-09  1147\n",
      "2021-03-16  1608\n",
      "2021-03-23  1488\n",
      "2021-03-30   945\n"
     ]
    }
   ],
   "source": [
    "print(mobility_analyser(df,start_date,end_date,\"Medellin\",10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandemic_stage_analyser(df:pd.DataFrame,start_date:datetime,end_date:datetime,city_filter: str,essential_or_luxury:str, epsilon:float):\n",
    "    \"\"\"final function to predict hotspots\"\"\"\n",
    "    bounds = (0, 600)\n",
    "    transaction_data_col = \"nb_transactions\"\n",
    "    groupby_col = \"date\"\n",
    "\n",
    "    city_col=\"city\"\n",
    "    time_col=\"date\"\n",
    "    merch_category_col=\"merch_super_category\"\n",
    "\n",
    "\n",
    "    \"\"\"time steps calculation\"\"\"\n",
    "    nb_timesteps = (end_date - start_date).days // 7\n",
    "\n",
    "    \"\"\"scale calculation\"\"\"\n",
    "    scale=(3.0*nb_timesteps*nb_timesteps)/epsilon\n",
    "\n",
    "    new_df=df.copy()\n",
    "\n",
    "\n",
    "    hotspot_predictor=(\n",
    "    make_preprocess_location()\n",
    "    >>make_preprocess_merchant()\n",
    "    >>make_filter(city_col,city_filter)\n",
    "    >>make_filter(merch_category_col,essential_or_luxury)\n",
    "    >>make_truncate_time(start_date, end_date, time_col)\n",
    "    >>make_private_sum_by(transaction_data_col, groupby_col, bounds, scale)\n",
    "   )\n",
    "\n",
    "    return hotspot_predictor(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0\n",
      "date              \n",
      "2020-09-01  119525\n",
      "2020-09-08  122797\n",
      "2020-09-15  117481\n",
      "2020-09-22  123151\n",
      "2020-09-29  115222\n",
      "2020-10-06  118614\n",
      "2020-10-13  117163\n",
      "2020-10-20  117853\n",
      "2020-10-27  116842\n",
      "2020-11-03  117436\n",
      "2020-11-10  124451\n",
      "2020-11-17  115435\n",
      "2020-11-24  117502\n",
      "2020-12-01  117037\n",
      "2020-12-08  110991\n",
      "2020-12-15  108300\n",
      "2020-12-22  114715\n",
      "2020-12-29  107363\n",
      "2021-01-05  106208\n",
      "2021-01-12  105092\n",
      "2021-01-19  109456\n",
      "2021-01-26  115614\n",
      "2021-02-02  122143\n",
      "2021-02-09  125693\n",
      "2021-02-16  127317\n",
      "2021-02-23  131396\n",
      "2021-03-02  133496\n",
      "2021-03-09  126942\n",
      "2021-03-16  122216\n",
      "2021-03-23  118228\n",
      "2021-03-30  112776\n"
     ]
    }
   ],
   "source": [
    "print(pandemic_stage_analyser(df,start_date,end_date,\"Medellin\",essential_or_luxrious=\"luxury\",epsilon=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenDPException",
     "evalue": "\n  FFI(\"Continued stack trace from Exception in user-defined function:\nTraceback (most recent call last):\n  File \"c:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\_convert.py\", line 459, in wrapper_func\n    py_out = func(py_arg)\n             ^^^^^^^^^^^^\n  File \"C:\\Users\\kshub\\AppData\\Local\\Temp\\ipykernel_22960\\4272251858.py\", line 5, in function\n    df = df.copy()\n         ^^^^^^^\nAttributeError: 'int' object has no attribute 'copy'\n\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenDPException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[157], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scale\u001b[38;5;241m=\u001b[39m\u001b[43mdp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_search_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhotspot_predictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(scale)\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\mod.py:814\u001b[0m, in \u001b[0;36mbinary_search_param\u001b[1;34m(make_chain, d_in, d_out, bounds, T)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Solve for the ideal constructor argument to `make_chain`.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;124;03mOptimizes a parameterized chain `make_chain` within float or integer `bounds`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;124;03m1498\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;66;03m# one might think running scipy.optimize.brent* would be better, but \u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# 1. benchmarking showed no difference or minor regressions\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;66;03m# 2. brentq is more complicated\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_search\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmake_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_out\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\mod.py:914\u001b[0m, in \u001b[0;36mbinary_search\u001b[1;34m(predicate, bounds, T, return_sign)\u001b[0m\n\u001b[0;32m    911\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbounds must share the same type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    912\u001b[0m lower, upper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(bounds)\n\u001b[1;32m--> 914\u001b[0m maximize \u001b[38;5;241m=\u001b[39m \u001b[43mpredicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# if the lower bound passes, we should maximize\u001b[39;00m\n\u001b[0;32m    915\u001b[0m minimize \u001b[38;5;241m=\u001b[39m predicate(upper)  \u001b[38;5;66;03m# if the upper bound passes, we should minimize\u001b[39;00m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maximize \u001b[38;5;241m==\u001b[39m minimize:\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\mod.py:814\u001b[0m, in \u001b[0;36mbinary_search_param.<locals>.<lambda>\u001b[1;34m(param)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Solve for the ideal constructor argument to `make_chain`.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;124;03mOptimizes a parameterized chain `make_chain` within float or integer `bounds`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;124;03m1498\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;66;03m# one might think running scipy.optimize.brent* would be better, but \u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# 1. benchmarking showed no difference or minor regressions\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;66;03m# 2. brentq is more complicated\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m binary_search(\u001b[38;5;28;01mlambda\u001b[39;00m param: \u001b[43mmake_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcheck(d_in, d_out), bounds, T)\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\mod.py:69\u001b[0m, in \u001b[0;36mMeasurement.__call__\u001b[1;34m(self, arg)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopendp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m measurement_invoke\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeasurement_invoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\core.py:380\u001b[0m, in \u001b[0;36mmeasurement_invoke\u001b[1;34m(this, arg)\u001b[0m\n\u001b[0;32m    377\u001b[0m lib_function\u001b[38;5;241m.\u001b[39margtypes \u001b[38;5;241m=\u001b[39m [Measurement, AnyObjectPtr]\n\u001b[0;32m    378\u001b[0m lib_function\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m FfiResult\n\u001b[1;32m--> 380\u001b[0m output \u001b[38;5;241m=\u001b[39m c_to_py(\u001b[43munwrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlib_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_this\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_arg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAnyObjectPtr\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\_lib.py:251\u001b[0m, in \u001b[0;36munwrap\u001b[1;34m(result, type_)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenDPException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to free error.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# Rust stack traces follow from here:\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OpenDPException(variant, message, backtrace)\n",
      "\u001b[1;31mOpenDPException\u001b[0m: \n  FFI(\"Continued stack trace from Exception in user-defined function:\nTraceback (most recent call last):\n  File \"c:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\_convert.py\", line 459, in wrapper_func\n    py_out = func(py_arg)\n             ^^^^^^^^^^^^\n  File \"C:\\Users\\kshub\\AppData\\Local\\Temp\\ipykernel_22960\\4272251858.py\", line 5, in function\n    df = df.copy()\n         ^^^^^^^\nAttributeError: 'int' object has no attribute 'copy'\n\")"
     ]
    }
   ],
   "source": [
    "scale=dp.binary_search_param(hotspot_predictor, 1,1.0,bounds=bounds)\n",
    "print(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenDPException",
     "evalue": "\n  FFI(\"Continued stack trace from Exception in user-defined function:\nTraceback (most recent call last):\n  File \"c:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\_convert.py\", line 459, in wrapper_func\n    py_out = func(py_arg)\n             ^^^^^^^^^^^^\n  File \"C:\\Users\\kshub\\AppData\\Local\\Temp\\ipykernel_22960\\257734847.py\", line 8, in <lambda>\n    function=lambda df: df[(df[\"transaction_type\"] == \"OFFLINE\")],\n                            ~~^^^^^^^^^^^^^^^^^^^^\nTypeError: 'int' object is not subscriptable\n\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenDPException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[122], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m analysis\u001b[38;5;241m=\u001b[39m\u001b[43mdp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_search_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhotspot_predictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\mod.py:746\u001b[0m, in \u001b[0;36mbinary_search_chain\u001b[1;34m(make_chain, d_in, d_out, bounds, T)\u001b[0m\n\u001b[0;32m    684\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbinary_search_chain\u001b[39m(\n\u001b[0;32m    685\u001b[0m         make_chain: Callable[[\u001b[38;5;28mfloat\u001b[39m], M],\n\u001b[0;32m    686\u001b[0m         d_in: Any, d_out: Any,\n\u001b[0;32m    687\u001b[0m         bounds: Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    688\u001b[0m         T\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m M:\n\u001b[0;32m    689\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the highest-utility (`d_in`, `d_out`)-close Transformation or Measurement.\u001b[39;00m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;124;03m    Searches for the numeric parameter to `make_chain` that results in a computation\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;124;03m    >>> # If you want the discovered clamping bound, use `binary_search_param` instead.\u001b[39;00m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 746\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m make_chain(\u001b[43mbinary_search_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmake_chain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\mod.py:814\u001b[0m, in \u001b[0;36mbinary_search_param\u001b[1;34m(make_chain, d_in, d_out, bounds, T)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Solve for the ideal constructor argument to `make_chain`.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;124;03mOptimizes a parameterized chain `make_chain` within float or integer `bounds`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;124;03m1498\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;66;03m# one might think running scipy.optimize.brent* would be better, but \u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# 1. benchmarking showed no difference or minor regressions\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;66;03m# 2. brentq is more complicated\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_search\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmake_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_out\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\mod.py:914\u001b[0m, in \u001b[0;36mbinary_search\u001b[1;34m(predicate, bounds, T, return_sign)\u001b[0m\n\u001b[0;32m    911\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbounds must share the same type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    912\u001b[0m lower, upper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(bounds)\n\u001b[1;32m--> 914\u001b[0m maximize \u001b[38;5;241m=\u001b[39m \u001b[43mpredicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# if the lower bound passes, we should maximize\u001b[39;00m\n\u001b[0;32m    915\u001b[0m minimize \u001b[38;5;241m=\u001b[39m predicate(upper)  \u001b[38;5;66;03m# if the upper bound passes, we should minimize\u001b[39;00m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maximize \u001b[38;5;241m==\u001b[39m minimize:\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\mod.py:814\u001b[0m, in \u001b[0;36mbinary_search_param.<locals>.<lambda>\u001b[1;34m(param)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Solve for the ideal constructor argument to `make_chain`.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;124;03mOptimizes a parameterized chain `make_chain` within float or integer `bounds`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;124;03m1498\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;66;03m# one might think running scipy.optimize.brent* would be better, but \u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# 1. benchmarking showed no difference or minor regressions\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;66;03m# 2. brentq is more complicated\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m binary_search(\u001b[38;5;28;01mlambda\u001b[39;00m param: \u001b[43mmake_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcheck(d_in, d_out), bounds, T)\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\mod.py:69\u001b[0m, in \u001b[0;36mMeasurement.__call__\u001b[1;34m(self, arg)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopendp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m measurement_invoke\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeasurement_invoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\core.py:380\u001b[0m, in \u001b[0;36mmeasurement_invoke\u001b[1;34m(this, arg)\u001b[0m\n\u001b[0;32m    377\u001b[0m lib_function\u001b[38;5;241m.\u001b[39margtypes \u001b[38;5;241m=\u001b[39m [Measurement, AnyObjectPtr]\n\u001b[0;32m    378\u001b[0m lib_function\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m FfiResult\n\u001b[1;32m--> 380\u001b[0m output \u001b[38;5;241m=\u001b[39m c_to_py(\u001b[43munwrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlib_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_this\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_arg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAnyObjectPtr\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\_lib.py:251\u001b[0m, in \u001b[0;36munwrap\u001b[1;34m(result, type_)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenDPException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to free error.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# Rust stack traces follow from here:\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OpenDPException(variant, message, backtrace)\n",
      "\u001b[1;31mOpenDPException\u001b[0m: \n  FFI(\"Continued stack trace from Exception in user-defined function:\nTraceback (most recent call last):\n  File \"c:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\_convert.py\", line 459, in wrapper_func\n    py_out = func(py_arg)\n             ^^^^^^^^^^^^\n  File \"C:\\Users\\kshub\\AppData\\Local\\Temp\\ipykernel_22960\\257734847.py\", line 8, in <lambda>\n    function=lambda df: df[(df[\"transaction_type\"] == \"OFFLINE\")],\n                            ~~^^^^^^^^^^^^^^^^^^^^\nTypeError: 'int' object is not subscriptable\n\")"
     ]
    }
   ],
   "source": [
    "analysis=dp.binary_search_chain(hotspot_predictor, 1,1.0,bounds=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30917.40000000001\n",
      "                        0\n",
      "merch_postal_code        \n",
      "7071                45765\n",
      "55411              183692\n",
      "70040               31856\n",
      "70050               27510\n",
      "70070               43102\n",
      "...                   ...\n",
      "9670000            108717\n",
      "9710000            106582\n",
      "9750000             84828\n",
      "9790000            128256\n",
      "9810000             83009\n",
      "\n",
      "[303 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df_new = df.copy()\n",
    "bounds = (0, 454)\n",
    "start_date, end_date = datetime(2020, 9, 1), datetime(2021, 3, 31)\n",
    "columns = [\"nb_transactions\"]\n",
    "by = [\"merch_postal_code\"]\n",
    "scale=10.0\n",
    "column=\"transaction_type\"\n",
    "entry=\"OFFLINE\"\n",
    "hotspot_predictor=(\n",
    "    make_filter_offline(column,entry)\n",
    "    >>make_truncate_time(start_date, end_date, time_col)\n",
    "    >>make_private_sum_by(columns, by, bounds, scale)\n",
    ")\n",
    "print(hotspot_predictor.map(1))\n",
    "output=hotspot_predictor(df_new)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30917.40000000001\n",
      "                                 0\n",
      "merch_postal_code date            \n",
      "7071              2020-09-01  2014\n",
      "                  2020-09-08  1946\n",
      "                  2020-09-15  1923\n",
      "                  2020-09-22  1940\n",
      "                  2020-09-29  1896\n",
      "...                            ...\n",
      "9810000           2021-03-02  1836\n",
      "                  2021-03-09  1851\n",
      "                  2021-03-16  1899\n",
      "                  2021-03-23  1907\n",
      "                  2021-03-30  1923\n",
      "\n",
      "[9238 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df_new = df.copy()\n",
    "bounds = (0, 454)\n",
    "start_date, end_date = datetime(2020, 9, 1), datetime(2021, 3, 31)\n",
    "columns = [\"nb_transactions\"]\n",
    "by = [\"merch_postal_code\",\"date\"]\n",
    "scale=10.0\n",
    "column=\"merch_category\"\n",
    "entry=\"Drug Stores/Pharmacies\"\n",
    "hotspot_predictor=(\n",
    "    make_filter_offline(column,entry)\n",
    "    >>make_truncate_time(start_date, end_date, time_col)\n",
    "    >>make_private_sum_by(columns, by, bounds, scale)\n",
    ")\n",
    "print(hotspot_predictor.map(1))\n",
    "output=hotspot_predictor(df_new)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30917.40000000001\n",
      "                               0\n",
      "merch_postal_code date          \n",
      "7071              2020-09-01   9\n",
      "                  2020-09-08  25\n",
      "                  2020-09-15  18\n",
      "                  2020-09-22   0\n",
      "                  2020-09-29   6\n",
      "...                           ..\n",
      "9810000           2021-03-02  58\n",
      "                  2021-03-09  59\n",
      "                  2021-03-16  71\n",
      "                  2021-03-23  53\n",
      "                  2021-03-30  65\n",
      "\n",
      "[6291 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df_new = df.copy()\n",
    "bounds = (0, 454)\n",
    "start_date, end_date = datetime(2020, 9, 1), datetime(2021, 3, 31)\n",
    "columns = [\"nb_transactions\"]\n",
    "by = [\"merch_postal_code\",\"date\"]\n",
    "scale=10.0\n",
    "column=\"merch_category\"\n",
    "entry=\"Airlines\"\n",
    "hotspot_predictor=(\n",
    "    make_filter_offline(column,entry)\n",
    "    >>make_truncate_time(start_date, end_date, time_col)\n",
    "    >>make_private_sum_by(columns, by, bounds, scale)\n",
    ")\n",
    "print(hotspot_predictor.map(1))\n",
    "output=hotspot_predictor(df_new)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_select_grouping_cols(candidates, min_bin_size, d_in, d_out):\n",
    "    \"\"\"Create a measurement that selects a set of grouping columns from `candidates`.\"\"\"\n",
    "    def make(s):\n",
    "        return (\n",
    "            make_grouping_cols_score(candidates, min_bin_size)\n",
    "            >> dp.m.then_report_noisy_max_gumbel(s, optimize=\"max\")\n",
    "            >> (lambda idx: candidates[idx])\n",
    "        )\n",
    "\n",
    "    return dp.binary_search_chain(make, d_in, d_out, T=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hotspot_detection(df, start_date, end_date, time_col):\n",
    "    \"\"\"DP function that detects hotspots.\"\"\"\n",
    "    df_new = df.copy()\n",
    "    bounds = (0, 454)\n",
    "\n",
    "    def make_filter_offline():\n",
    "        \"\"\"filters offline entries\"\"\"\n",
    "        return dp.t.make_user_transformation(\n",
    "        input_domain=dataframe_domain(),\n",
    "        input_metric=dp.symmetric_distance(),\n",
    "        output_domain=dp.vector_domain(dp.atom_domain(T=T)),\n",
    "        output_metric=dp.symmetric_distance(),\n",
    "        function=lambda df: df[(df[\"transaction_type\"] == \"OFFLINE\")],\n",
    "        stability_map=lambda d_in: d_in,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    make_filter_offline>>make_truncate_time(start_date, end_date, time_col)>>make_private_sum_by()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
