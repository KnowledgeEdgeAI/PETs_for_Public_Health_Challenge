{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from utilities import *\n",
    "import opendp.prelude as dp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:8: SyntaxWarning: invalid escape sequence '\\k'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\k'\n",
      "C:\\Users\\kshub\\AppData\\Local\\Temp\\ipykernel_22960\\3898676667.py:8: SyntaxWarning: invalid escape sequence '\\k'\n",
      "  path = \"C:\\\\Users\\kshub\\\\OneDrive\\\\Documents\\\\PET_phase_2\\\\Technical_Phase_Data\\\\technical_phase_data.csv\"\n"
     ]
    }
   ],
   "source": [
    "dp.enable_features(\"contrib\", \"floating-point\", \"honest-but-curious\")\n",
    "\n",
    "# PUBLIC INFO\n",
    "start_date, end_date = datetime(2020, 9, 1), datetime(2021, 3, 31)\n",
    "time_col = \"date\"\n",
    "\n",
    "# DATA\n",
    "path = \"C:\\\\Users\\kshub\\\\OneDrive\\\\Documents\\\\PET_phase_2\\\\Technical_Phase_Data\\\\technical_phase_data.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_domain(public_key_sets=None):\n",
    "    \"\"\"Creates a domain representing the set of all data frames.\n",
    "    \n",
    "    Assumes column names and types are public information.\n",
    "    Key sets optionally named for columns in `public_key_sets` are considered public information.\n",
    "\n",
    "    Two data frames differing in their public information \n",
    "    are considered to have a data set distance of infinity.\n",
    "    \"\"\"\n",
    "    return dp.user_domain(\n",
    "        \"DataFrameDomain\", lambda x: isinstance(x, pd.DataFrame), public_key_sets\n",
    "    )\n",
    "\n",
    "\n",
    "def series_domain():\n",
    "    \"\"\"Creates a domain representing the set of all series.\n",
    "\n",
    "    Assumes series name and type are public information.\n",
    "\n",
    "    Two series differing in their public information \n",
    "    are considered to have a data set distance of infinity.\n",
    "    \"\"\"\n",
    "    return dp.user_domain(\"SeriesDomain\", lambda x: isinstance(x, pd.Series))\n",
    "\n",
    "def identifier_distance():\n",
    "    \"\"\"Symmetric distance between the id sets.\"\"\"\n",
    "    return dp.user_distance(\"IdentifierDistance\")\n",
    "\n",
    "\n",
    "def approx_concentrated_divergence():\n",
    "    \"\"\"symmetric distance between the id sets\"\"\"\n",
    "    return dp.user_distance(\"ApproxConcentratedDivergence()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocess_location():\n",
    "    \"\"\"Create a 1-stable transformation to bin `merch_postal_code` by city\"\"\"\n",
    "\n",
    "    def categorize_city(code):\n",
    "        if code.startswith(\"5\"):\n",
    "            return \"Medellin\"\n",
    "        elif code.startswith(\"11\"):\n",
    "            return \"Bogota\"\n",
    "        elif code.startswith(\"70\"):\n",
    "            return \"Brasilia\"\n",
    "        else:\n",
    "            return \"Santiago\"\n",
    "\n",
    "    def location_preprocess(df):\n",
    "        loc_df = df.copy()\n",
    "        # Convert merchant_postal_code into str type\n",
    "        loc_df[\"merch_postal_code\"] = loc_df[\"merch_postal_code\"].astype(str)\n",
    "        # Apply the function to create a new column\n",
    "        loc_df[\"city\"] = loc_df[\"merch_postal_code\"].apply(\n",
    "            categorize_city\n",
    "        )\n",
    "        return loc_df\n",
    "\n",
    "    return dp.t.make_user_transformation(\n",
    "        input_domain=dataframe_domain(),\n",
    "        input_metric=identifier_distance(),\n",
    "        output_domain=dataframe_domain(),\n",
    "        output_metric=identifier_distance(),\n",
    "        function=location_preprocess,\n",
    "        stability_map=lambda d_in: d_in,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocess_merchant():\n",
    "    \"\"\"Create a 1-stable transformation to bin `merch_postal_code` by city\"\"\"\n",
    "\n",
    "    def categorize_merchant(merch):\n",
    "        if merch in ['Hotels/Motels','Restaurants','Bars/Discotheques']:\n",
    "            return \"luxury\"\n",
    "        elif merch in ['Grocery Stores/Supermarkets','Drug Stores/Pharmacies','General Retail Stores','Utilities: Electric, Gas, Water','Hospitals']:\n",
    "            return \"essential\"\n",
    "        else:\n",
    "            return \"other\"\n",
    "\n",
    "    def merchant_preprocess(df):\n",
    "        loc_df = df.copy()\n",
    "        # Convert merchant_postal_code into str type\n",
    "        loc_df[\"merch_category\"] = loc_df[\"merch_category\"].astype(str)\n",
    "        # Apply the function to create a new column\n",
    "        loc_df[\"merch_super_category\"] = loc_df[\"merch_category\"].apply(\n",
    "            categorize_merchant\n",
    "        )\n",
    "        return loc_df\n",
    "\n",
    "    return dp.t.make_user_transformation(\n",
    "        input_domain=dataframe_domain(),\n",
    "        input_metric=identifier_distance(),\n",
    "        output_domain=dataframe_domain(),\n",
    "        output_metric=identifier_distance(),\n",
    "        function=merchant_preprocess,\n",
    "        stability_map=lambda d_in: d_in,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_truncate_time(start_date, end_date, time_col):\n",
    "    \"\"\"Create a transformation that filters the data to a given time frame.\n",
    "    \n",
    "    WARNING: Assumes that the data has at most one contribution per individual per week.\n",
    "    \"\"\"\n",
    "    number_of_timesteps = (end_date - start_date).days // 7\n",
    "\n",
    "    def time_preprocess(df):\n",
    "        df = df.copy()\n",
    "\n",
    "        # Convert time_col into datetime type\n",
    "        df[time_col] = pd.to_datetime(df[time_col])\n",
    "\n",
    "        # Filter the DataFrame based on the specified dates\n",
    "        return df[(df[time_col] >= start_date) & (df[time_col] <= end_date)]\n",
    "\n",
    "    return dp.t.make_user_transformation(\n",
    "        input_domain=dataframe_domain(),\n",
    "        input_metric=identifier_distance(),\n",
    "        output_domain=dataframe_domain(),\n",
    "        output_metric=dp.symmetric_distance(),\n",
    "        function=time_preprocess,\n",
    "        stability_map=lambda d_in: d_in * number_of_timesteps,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sum_by(column, by, bounds):\n",
    "    \"\"\"Create a transformation that computes the grouped bounded sum of `column`\"\"\"\n",
    "    L, U = bounds\n",
    "    # print(df.head())\n",
    "    def function(df):\n",
    "        df = df.copy()\n",
    "        # print(df.head())\n",
    "        df[column] = df[column].clip(*bounds)\n",
    "        return df.groupby(by)[column].sum()\n",
    "\n",
    "    return dp.t.make_user_transformation(\n",
    "        input_domain=dataframe_domain(),\n",
    "        input_metric=dp.symmetric_distance(),\n",
    "        output_domain=series_domain(),\n",
    "        output_metric=dp.l2_distance(T=float),\n",
    "        function=function,\n",
    "        stability_map=lambda d_in: np.sqrt(d_in) * max(abs(L), U),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maximum nb_transaction entry for any category is 454. Assuming the bound of [0, 454]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_private_sum_by(column, by, bounds, scale):\n",
    "    \"\"\"Create a measurement that computes the grouped bounded sum of `column`\"\"\"\n",
    "    space = dp.vector_domain(dp.atom_domain(T=int)), dp.l2_distance(T=float)\n",
    "    m_gauss = space >> dp.m.then_gaussian(scale)\n",
    "    t_sum = make_sum_by(column, by, bounds)\n",
    "\n",
    "    def function(df):\n",
    "        exact = t_sum(df)\n",
    "        # print(exact)\n",
    "        # print(exact.to_numpy())\n",
    "        noisy_sum = pd.Series(\n",
    "            np.maximum(m_gauss(exact.to_numpy().flatten()), 0), index=exact.index\n",
    "        )\n",
    "        return noisy_sum.to_frame()\n",
    "\n",
    "    return dp.m.make_user_measurement(\n",
    "        input_domain=dataframe_domain(public_key_sets=[by]),\n",
    "        input_metric=dp.symmetric_distance(),\n",
    "        output_measure=dp.zero_concentrated_divergence(T=float),\n",
    "        function=function,\n",
    "        privacy_map=lambda d_in: m_gauss.map(t_sum.map(d_in)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filter(column,entry, sensetivity:int= 1):\n",
    "        \"\"\"filters offline entries\"\"\"\n",
    "        \n",
    "        def function(df):\n",
    "            df = df.copy()\n",
    "            return df[(df[column] == entry)]\n",
    "\n",
    "\n",
    "        return dp.t.make_user_transformation(\n",
    "        input_domain=dataframe_domain(),\n",
    "        input_metric=identifier_distance(),\n",
    "        output_domain=dataframe_domain(),\n",
    "        output_metric=identifier_distance(),\n",
    "        function=function,\n",
    "        stability_map=lambda d_in: d_in* sensetivity,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30917.40000000001\n",
      "                        0\n",
      "merch_postal_code        \n",
      "500001             182278\n",
      "500002             184203\n",
      "500003             181031\n",
      "500004             178535\n",
      "500005             202209\n",
      "500006             189736\n",
      "500007             205075\n",
      "500008             166502\n",
      "500009             194875\n",
      "500010             188914\n",
      "500011             175243\n",
      "500012             165526\n",
      "500013             190525\n",
      "500014             214841\n",
      "500015             191984\n",
      "500016             192572\n",
      "500017             193764\n",
      "500020             218498\n",
      "500021             205332\n",
      "500022             214301\n",
      "500023             185691\n",
      "500024             212903\n",
      "500025             206197\n",
      "500026             185104\n",
      "500027             202576\n",
      "500028             180739\n",
      "500030             207620\n",
      "500031             207334\n",
      "500032             221125\n",
      "500033             193689\n",
      "500034             176485\n",
      "500035             190021\n",
      "500036             176725\n",
      "500037             163625\n",
      "500040             178749\n",
      "500041             185477\n",
      "500042             188734\n",
      "500043             228702\n",
      "500044             165497\n",
      "500046             182967\n",
      "500047             190205\n",
      "55411              183700\n"
     ]
    }
   ],
   "source": [
    "df_new = df.copy()\n",
    "bounds = (0, 454)\n",
    "start_date, end_date = datetime(2020, 9, 1), datetime(2021, 3, 31)\n",
    "columns = \"nb_transactions\"\n",
    "by = \"merch_postal_code\"\n",
    "scale=10.0\n",
    "column=\"transaction_type\"\n",
    "entry=\"OFFLINE\"\n",
    "city_col=\"city\"\n",
    "City_entry=\"Medellin\"\n",
    "hotspot_predictor=(\n",
    "    make_preprocess_location()\n",
    "    >>make_filter(column,entry)\n",
    "    >>make_filter(city_col,City_entry)\n",
    "    >>make_truncate_time(start_date, end_date, time_col)\n",
    "    >>make_private_sum_by(columns, by, bounds, scale)\n",
    ")\n",
    "print(hotspot_predictor.map(1))\n",
    "output=hotspot_predictor(df_new)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hotspot_analyser(df:pd.DataFrame, start_date:datetime,end_date:datetime,city_filter:str, nb_postal_codes: int,epsilon:float):\n",
    "    \"\"\"final function to predict hotspots\"\"\"\n",
    "    bounds = (0, 600)\n",
    "    transaction_data_col = \"nb_transactions\"\n",
    "    postal_code_groupby_col = \"merch_postal_code\"\n",
    "    transaction_type_col = \"transaction_type\"\n",
    "    transaction_type_filter = \"OFFLINE\"\n",
    "    city_col=\"city\"\n",
    "    time_col=\"date\"\n",
    "\n",
    "    \"\"\"time steps calculation\"\"\"\n",
    "    nb_timesteps = (end_date - start_date).days // 7\n",
    "\n",
    "    \"\"\"scale calculation\"\"\"\n",
    "    scale=(3.0*nb_postal_codes*nb_timesteps)/epsilon\n",
    "\n",
    "    new_df=df.copy()\n",
    "\n",
    "\n",
    "    hotspot_predictor=(\n",
    "    make_preprocess_location()\n",
    "    >>make_filter(transaction_type_col,transaction_type_filter)\n",
    "    >>make_filter(city_col,city_filter,nb_postal_codes)\n",
    "    >>make_truncate_time(start_date, end_date, time_col)\n",
    "    >>make_private_sum_by(transaction_data_col, postal_code_groupby_col, bounds, scale)\n",
    "   )\n",
    "\n",
    "    return hotspot_predictor(new_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        0\n",
      "merch_postal_code        \n",
      "500001             182127\n",
      "500002             184834\n",
      "500003             180723\n",
      "500004             178663\n",
      "500005             202160\n",
      "500006             190032\n",
      "500007             204808\n",
      "500008             166404\n",
      "500009             194555\n",
      "500010             189101\n",
      "500011             175437\n",
      "500012             165264\n",
      "500013             190181\n",
      "500014             214967\n",
      "500015             191939\n",
      "500016             193132\n",
      "500017             194186\n",
      "500020             218432\n",
      "500021             205058\n",
      "500022             215002\n",
      "500023             186325\n",
      "500024             213090\n",
      "500025             206436\n",
      "500026             185552\n",
      "500027             203101\n",
      "500028             180149\n",
      "500030             207686\n",
      "500031             207353\n",
      "500032             221942\n",
      "500033             193726\n",
      "500034             177103\n",
      "500035             189928\n",
      "500036             176520\n",
      "500037             163407\n",
      "500040             178941\n",
      "500041             185563\n",
      "500042             188988\n",
      "500043             228932\n",
      "500044             165859\n",
      "500046             182936\n",
      "500047             190162\n",
      "55411              183695\n"
     ]
    }
   ],
   "source": [
    "print(hotspot_analyser(df,start_date,end_date,\"Medellin\",42,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobility_analyser(df:pd.DataFrame,start_date:datetime,end_date:datetime,city_filter: str, epsilon:float):\n",
    "    \"\"\"final function to predict hotspots\"\"\"\n",
    "    bounds = (0, 600)\n",
    "    transaction_data_col = \"nb_transactions\"\n",
    "    groupby_col = \"date\"\n",
    "\n",
    "    city_col=\"city\"\n",
    "    time_col=\"date\"\n",
    "    merch_category_col=\"merch_category\"\n",
    "    merch_filter=\"Airlines\"\n",
    "\n",
    "    \"\"\"time steps calculation\"\"\"\n",
    "    nb_timesteps = (end_date - start_date).days // 7\n",
    "\n",
    "    \"\"\"scale calculation\"\"\"\n",
    "    scale=(3.0*nb_timesteps*nb_timesteps)/epsilon\n",
    "\n",
    "    new_df=df.copy()\n",
    "\n",
    "\n",
    "    hotspot_predictor=(\n",
    "    make_preprocess_location()\n",
    "    >>make_filter(city_col,city_filter)\n",
    "    >>make_filter(merch_category_col,merch_filter)\n",
    "    >>make_truncate_time(start_date, end_date, time_col)\n",
    "    >>make_private_sum_by(transaction_data_col, groupby_col, bounds, scale)\n",
    "   )\n",
    "\n",
    "    return hotspot_predictor(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0\n",
      "date            \n",
      "2020-09-01  1418\n",
      "2020-09-08   860\n",
      "2020-09-15  1273\n",
      "2020-09-22  1278\n",
      "2020-09-29   937\n",
      "2020-10-06  1413\n",
      "2020-10-13  1185\n",
      "2020-10-20  1055\n",
      "2020-10-27   981\n",
      "2020-11-03  1431\n",
      "2020-11-10  1260\n",
      "2020-11-17  1270\n",
      "2020-11-24  1736\n",
      "2020-12-01  1331\n",
      "2020-12-08  1081\n",
      "2020-12-15  1601\n",
      "2020-12-22  1591\n",
      "2020-12-29  1300\n",
      "2021-01-05  1082\n",
      "2021-01-12  1873\n",
      "2021-01-19  1244\n",
      "2021-01-26  1223\n",
      "2021-02-02  1560\n",
      "2021-02-09  1747\n",
      "2021-02-16  1267\n",
      "2021-02-23  2057\n",
      "2021-03-02  1117\n",
      "2021-03-09  1147\n",
      "2021-03-16  1608\n",
      "2021-03-23  1488\n",
      "2021-03-30   945\n"
     ]
    }
   ],
   "source": [
    "print(mobility_analyser(df,start_date,end_date,\"Medellin\",10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandemic_stage_analyser(df:pd.DataFrame,start_date:datetime,end_date:datetime,city_filter: str,essential_or_luxury:str, epsilon:float):\n",
    "    \"\"\"final function to predict hotspots\"\"\"\n",
    "    bounds = (0, 600)\n",
    "    transaction_data_col = \"nb_transactions\"\n",
    "    groupby_col = \"date\"\n",
    "\n",
    "    city_col=\"city\"\n",
    "    time_col=\"date\"\n",
    "    merch_category_col=\"merch_super_category\"\n",
    "\n",
    "\n",
    "    \"\"\"time steps calculation\"\"\"\n",
    "    nb_timesteps = (end_date - start_date).days // 7\n",
    "\n",
    "    \"\"\"scale calculation\"\"\"\n",
    "    scale=(3.0*nb_timesteps*nb_timesteps)/epsilon\n",
    "\n",
    "    new_df=df.copy()\n",
    "\n",
    "\n",
    "    hotspot_predictor=(\n",
    "    make_preprocess_location()\n",
    "    >>make_preprocess_merchant()\n",
    "    >>make_filter(city_col,city_filter)\n",
    "    >>make_filter(merch_category_col,essential_or_luxury)\n",
    "    >>make_truncate_time(start_date, end_date, time_col)\n",
    "    >>make_private_sum_by(transaction_data_col, groupby_col, bounds, scale)\n",
    "   )\n",
    "\n",
    "    return hotspot_predictor(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0\n",
      "date              \n",
      "2020-09-01  119525\n",
      "2020-09-08  122797\n",
      "2020-09-15  117481\n",
      "2020-09-22  123151\n",
      "2020-09-29  115222\n",
      "2020-10-06  118614\n",
      "2020-10-13  117163\n",
      "2020-10-20  117853\n",
      "2020-10-27  116842\n",
      "2020-11-03  117436\n",
      "2020-11-10  124451\n",
      "2020-11-17  115435\n",
      "2020-11-24  117502\n",
      "2020-12-01  117037\n",
      "2020-12-08  110991\n",
      "2020-12-15  108300\n",
      "2020-12-22  114715\n",
      "2020-12-29  107363\n",
      "2021-01-05  106208\n",
      "2021-01-12  105092\n",
      "2021-01-19  109456\n",
      "2021-01-26  115614\n",
      "2021-02-02  122143\n",
      "2021-02-09  125693\n",
      "2021-02-16  127317\n",
      "2021-02-23  131396\n",
      "2021-03-02  133496\n",
      "2021-03-09  126942\n",
      "2021-03-16  122216\n",
      "2021-03-23  118228\n",
      "2021-03-30  112776\n"
     ]
    }
   ],
   "source": [
    "print(pandemic_stage_analyser(df,start_date,end_date,\"Medellin\",essential_or_luxrious=\"luxury\",epsilon=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenDPException",
     "evalue": "\n  FFI(\"Continued stack trace from Exception in user-defined function:\nTraceback (most recent call last):\n  File \"c:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\_convert.py\", line 459, in wrapper_func\n    py_out = func(py_arg)\n             ^^^^^^^^^^^^\n  File \"C:\\Users\\kshub\\AppData\\Local\\Temp\\ipykernel_22960\\4272251858.py\", line 5, in function\n    df = df.copy()\n         ^^^^^^^\nAttributeError: 'int' object has no attribute 'copy'\n\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenDPException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[157], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scale\u001b[38;5;241m=\u001b[39m\u001b[43mdp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_search_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhotspot_predictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(scale)\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\mod.py:814\u001b[0m, in \u001b[0;36mbinary_search_param\u001b[1;34m(make_chain, d_in, d_out, bounds, T)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Solve for the ideal constructor argument to `make_chain`.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;124;03mOptimizes a parameterized chain `make_chain` within float or integer `bounds`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;124;03m1498\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;66;03m# one might think running scipy.optimize.brent* would be better, but \u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# 1. benchmarking showed no difference or minor regressions\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;66;03m# 2. brentq is more complicated\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_search\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmake_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_out\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\mod.py:914\u001b[0m, in \u001b[0;36mbinary_search\u001b[1;34m(predicate, bounds, T, return_sign)\u001b[0m\n\u001b[0;32m    911\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbounds must share the same type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    912\u001b[0m lower, upper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(bounds)\n\u001b[1;32m--> 914\u001b[0m maximize \u001b[38;5;241m=\u001b[39m \u001b[43mpredicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# if the lower bound passes, we should maximize\u001b[39;00m\n\u001b[0;32m    915\u001b[0m minimize \u001b[38;5;241m=\u001b[39m predicate(upper)  \u001b[38;5;66;03m# if the upper bound passes, we should minimize\u001b[39;00m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maximize \u001b[38;5;241m==\u001b[39m minimize:\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\mod.py:814\u001b[0m, in \u001b[0;36mbinary_search_param.<locals>.<lambda>\u001b[1;34m(param)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Solve for the ideal constructor argument to `make_chain`.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;124;03mOptimizes a parameterized chain `make_chain` within float or integer `bounds`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;124;03m1498\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;66;03m# one might think running scipy.optimize.brent* would be better, but \u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# 1. benchmarking showed no difference or minor regressions\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;66;03m# 2. brentq is more complicated\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m binary_search(\u001b[38;5;28;01mlambda\u001b[39;00m param: \u001b[43mmake_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcheck(d_in, d_out), bounds, T)\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\mod.py:69\u001b[0m, in \u001b[0;36mMeasurement.__call__\u001b[1;34m(self, arg)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopendp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m measurement_invoke\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeasurement_invoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\core.py:380\u001b[0m, in \u001b[0;36mmeasurement_invoke\u001b[1;34m(this, arg)\u001b[0m\n\u001b[0;32m    377\u001b[0m lib_function\u001b[38;5;241m.\u001b[39margtypes \u001b[38;5;241m=\u001b[39m [Measurement, AnyObjectPtr]\n\u001b[0;32m    378\u001b[0m lib_function\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m FfiResult\n\u001b[1;32m--> 380\u001b[0m output \u001b[38;5;241m=\u001b[39m c_to_py(\u001b[43munwrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlib_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_this\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_arg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAnyObjectPtr\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\_lib.py:251\u001b[0m, in \u001b[0;36munwrap\u001b[1;34m(result, type_)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenDPException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to free error.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# Rust stack traces follow from here:\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OpenDPException(variant, message, backtrace)\n",
      "\u001b[1;31mOpenDPException\u001b[0m: \n  FFI(\"Continued stack trace from Exception in user-defined function:\nTraceback (most recent call last):\n  File \"c:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\_convert.py\", line 459, in wrapper_func\n    py_out = func(py_arg)\n             ^^^^^^^^^^^^\n  File \"C:\\Users\\kshub\\AppData\\Local\\Temp\\ipykernel_22960\\4272251858.py\", line 5, in function\n    df = df.copy()\n         ^^^^^^^\nAttributeError: 'int' object has no attribute 'copy'\n\")"
     ]
    }
   ],
   "source": [
    "scale=dp.binary_search_param(hotspot_predictor, 1,1.0,bounds=bounds)\n",
    "print(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenDPException",
     "evalue": "\n  FFI(\"Continued stack trace from Exception in user-defined function:\nTraceback (most recent call last):\n  File \"c:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\_convert.py\", line 459, in wrapper_func\n    py_out = func(py_arg)\n             ^^^^^^^^^^^^\n  File \"C:\\Users\\kshub\\AppData\\Local\\Temp\\ipykernel_22960\\257734847.py\", line 8, in <lambda>\n    function=lambda df: df[(df[\"transaction_type\"] == \"OFFLINE\")],\n                            ~~^^^^^^^^^^^^^^^^^^^^\nTypeError: 'int' object is not subscriptable\n\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenDPException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[122], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m analysis\u001b[38;5;241m=\u001b[39m\u001b[43mdp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_search_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhotspot_predictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\mod.py:746\u001b[0m, in \u001b[0;36mbinary_search_chain\u001b[1;34m(make_chain, d_in, d_out, bounds, T)\u001b[0m\n\u001b[0;32m    684\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbinary_search_chain\u001b[39m(\n\u001b[0;32m    685\u001b[0m         make_chain: Callable[[\u001b[38;5;28mfloat\u001b[39m], M],\n\u001b[0;32m    686\u001b[0m         d_in: Any, d_out: Any,\n\u001b[0;32m    687\u001b[0m         bounds: Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    688\u001b[0m         T\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m M:\n\u001b[0;32m    689\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the highest-utility (`d_in`, `d_out`)-close Transformation or Measurement.\u001b[39;00m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;124;03m    Searches for the numeric parameter to `make_chain` that results in a computation\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;124;03m    >>> # If you want the discovered clamping bound, use `binary_search_param` instead.\u001b[39;00m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 746\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m make_chain(\u001b[43mbinary_search_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmake_chain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\mod.py:814\u001b[0m, in \u001b[0;36mbinary_search_param\u001b[1;34m(make_chain, d_in, d_out, bounds, T)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Solve for the ideal constructor argument to `make_chain`.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;124;03mOptimizes a parameterized chain `make_chain` within float or integer `bounds`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;124;03m1498\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;66;03m# one might think running scipy.optimize.brent* would be better, but \u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# 1. benchmarking showed no difference or minor regressions\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;66;03m# 2. brentq is more complicated\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_search\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmake_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_out\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\mod.py:914\u001b[0m, in \u001b[0;36mbinary_search\u001b[1;34m(predicate, bounds, T, return_sign)\u001b[0m\n\u001b[0;32m    911\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbounds must share the same type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    912\u001b[0m lower, upper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(bounds)\n\u001b[1;32m--> 914\u001b[0m maximize \u001b[38;5;241m=\u001b[39m \u001b[43mpredicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# if the lower bound passes, we should maximize\u001b[39;00m\n\u001b[0;32m    915\u001b[0m minimize \u001b[38;5;241m=\u001b[39m predicate(upper)  \u001b[38;5;66;03m# if the upper bound passes, we should minimize\u001b[39;00m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maximize \u001b[38;5;241m==\u001b[39m minimize:\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\mod.py:814\u001b[0m, in \u001b[0;36mbinary_search_param.<locals>.<lambda>\u001b[1;34m(param)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Solve for the ideal constructor argument to `make_chain`.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;124;03mOptimizes a parameterized chain `make_chain` within float or integer `bounds`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;124;03m1498\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;66;03m# one might think running scipy.optimize.brent* would be better, but \u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# 1. benchmarking showed no difference or minor regressions\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;66;03m# 2. brentq is more complicated\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m binary_search(\u001b[38;5;28;01mlambda\u001b[39;00m param: \u001b[43mmake_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcheck(d_in, d_out), bounds, T)\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\mod.py:69\u001b[0m, in \u001b[0;36mMeasurement.__call__\u001b[1;34m(self, arg)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopendp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m measurement_invoke\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeasurement_invoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\core.py:380\u001b[0m, in \u001b[0;36mmeasurement_invoke\u001b[1;34m(this, arg)\u001b[0m\n\u001b[0;32m    377\u001b[0m lib_function\u001b[38;5;241m.\u001b[39margtypes \u001b[38;5;241m=\u001b[39m [Measurement, AnyObjectPtr]\n\u001b[0;32m    378\u001b[0m lib_function\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m FfiResult\n\u001b[1;32m--> 380\u001b[0m output \u001b[38;5;241m=\u001b[39m c_to_py(\u001b[43munwrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlib_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_this\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_arg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAnyObjectPtr\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\_lib.py:251\u001b[0m, in \u001b[0;36munwrap\u001b[1;34m(result, type_)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenDPException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to free error.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# Rust stack traces follow from here:\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OpenDPException(variant, message, backtrace)\n",
      "\u001b[1;31mOpenDPException\u001b[0m: \n  FFI(\"Continued stack trace from Exception in user-defined function:\nTraceback (most recent call last):\n  File \"c:\\Users\\kshub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\opendp\\_convert.py\", line 459, in wrapper_func\n    py_out = func(py_arg)\n             ^^^^^^^^^^^^\n  File \"C:\\Users\\kshub\\AppData\\Local\\Temp\\ipykernel_22960\\257734847.py\", line 8, in <lambda>\n    function=lambda df: df[(df[\"transaction_type\"] == \"OFFLINE\")],\n                            ~~^^^^^^^^^^^^^^^^^^^^\nTypeError: 'int' object is not subscriptable\n\")"
     ]
    }
   ],
   "source": [
    "analysis=dp.binary_search_chain(hotspot_predictor, 1,1.0,bounds=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30917.40000000001\n",
      "                        0\n",
      "merch_postal_code        \n",
      "7071                45765\n",
      "55411              183692\n",
      "70040               31856\n",
      "70050               27510\n",
      "70070               43102\n",
      "...                   ...\n",
      "9670000            108717\n",
      "9710000            106582\n",
      "9750000             84828\n",
      "9790000            128256\n",
      "9810000             83009\n",
      "\n",
      "[303 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df_new = df.copy()\n",
    "bounds = (0, 454)\n",
    "start_date, end_date = datetime(2020, 9, 1), datetime(2021, 3, 31)\n",
    "columns = [\"nb_transactions\"]\n",
    "by = [\"merch_postal_code\"]\n",
    "scale=10.0\n",
    "column=\"transaction_type\"\n",
    "entry=\"OFFLINE\"\n",
    "hotspot_predictor=(\n",
    "    make_filter_offline(column,entry)\n",
    "    >>make_truncate_time(start_date, end_date, time_col)\n",
    "    >>make_private_sum_by(columns, by, bounds, scale)\n",
    ")\n",
    "print(hotspot_predictor.map(1))\n",
    "output=hotspot_predictor(df_new)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30917.40000000001\n",
      "                                 0\n",
      "merch_postal_code date            \n",
      "7071              2020-09-01  2014\n",
      "                  2020-09-08  1946\n",
      "                  2020-09-15  1923\n",
      "                  2020-09-22  1940\n",
      "                  2020-09-29  1896\n",
      "...                            ...\n",
      "9810000           2021-03-02  1836\n",
      "                  2021-03-09  1851\n",
      "                  2021-03-16  1899\n",
      "                  2021-03-23  1907\n",
      "                  2021-03-30  1923\n",
      "\n",
      "[9238 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df_new = df.copy()\n",
    "bounds = (0, 454)\n",
    "start_date, end_date = datetime(2020, 9, 1), datetime(2021, 3, 31)\n",
    "columns = [\"nb_transactions\"]\n",
    "by = [\"merch_postal_code\",\"date\"]\n",
    "scale=10.0\n",
    "column=\"merch_category\"\n",
    "entry=\"Drug Stores/Pharmacies\"\n",
    "hotspot_predictor=(\n",
    "    make_filter_offline(column,entry)\n",
    "    >>make_truncate_time(start_date, end_date, time_col)\n",
    "    >>make_private_sum_by(columns, by, bounds, scale)\n",
    ")\n",
    "print(hotspot_predictor.map(1))\n",
    "output=hotspot_predictor(df_new)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30917.40000000001\n",
      "                               0\n",
      "merch_postal_code date          \n",
      "7071              2020-09-01   9\n",
      "                  2020-09-08  25\n",
      "                  2020-09-15  18\n",
      "                  2020-09-22   0\n",
      "                  2020-09-29   6\n",
      "...                           ..\n",
      "9810000           2021-03-02  58\n",
      "                  2021-03-09  59\n",
      "                  2021-03-16  71\n",
      "                  2021-03-23  53\n",
      "                  2021-03-30  65\n",
      "\n",
      "[6291 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df_new = df.copy()\n",
    "bounds = (0, 454)\n",
    "start_date, end_date = datetime(2020, 9, 1), datetime(2021, 3, 31)\n",
    "columns = [\"nb_transactions\"]\n",
    "by = [\"merch_postal_code\",\"date\"]\n",
    "scale=10.0\n",
    "column=\"merch_category\"\n",
    "entry=\"Airlines\"\n",
    "hotspot_predictor=(\n",
    "    make_filter_offline(column,entry)\n",
    "    >>make_truncate_time(start_date, end_date, time_col)\n",
    "    >>make_private_sum_by(columns, by, bounds, scale)\n",
    ")\n",
    "print(hotspot_predictor.map(1))\n",
    "output=hotspot_predictor(df_new)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_select_grouping_cols(candidates, min_bin_size, d_in, d_out):\n",
    "    \"\"\"Create a measurement that selects a set of grouping columns from `candidates`.\"\"\"\n",
    "    def make(s):\n",
    "        return (\n",
    "            make_grouping_cols_score(candidates, min_bin_size)\n",
    "            >> dp.m.then_report_noisy_max_gumbel(s, optimize=\"max\")\n",
    "            >> (lambda idx: candidates[idx])\n",
    "        )\n",
    "\n",
    "    return dp.binary_search_chain(make, d_in, d_out, T=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hotspot_detection(df, start_date, end_date, time_col):\n",
    "    \"\"\"DP function that detects hotspots.\"\"\"\n",
    "    df_new = df.copy()\n",
    "    bounds = (0, 454)\n",
    "\n",
    "    def make_filter_offline():\n",
    "        \"\"\"filters offline entries\"\"\"\n",
    "        return dp.t.make_user_transformation(\n",
    "        input_domain=dataframe_domain(),\n",
    "        input_metric=dp.symmetric_distance(),\n",
    "        output_domain=dp.vector_domain(dp.atom_domain(T=T)),\n",
    "        output_metric=dp.symmetric_distance(),\n",
    "        function=lambda df: df[(df[\"transaction_type\"] == \"OFFLINE\")],\n",
    "        stability_map=lambda d_in: d_in,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    make_filter_offline>>make_truncate_time(start_date, end_date, time_col)>>make_private_sum_by()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
